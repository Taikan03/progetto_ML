# -*- coding: utf-8 -*-
"""ProgettoML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c-BeErZuUzcwIfyeoDnUoVbtDB4V6n7A

LIBRERIE(quando si installano le librerie bisogna riavviare la sessione perché la versione di numpy che viene installata con audiocraft fa riscontro con la versione di numpy in colab)
"""

!pip install torch torchvision torchaudio --index-url https://download.pytor
!pip install transformers==4.41.0
!pip install pyloudnorm
!pip install git+https://github.com/facebookresearch/audiocraft.git
!pip install noisereduce

"""OPERAZIONI"""
-----
#creazione traccia audio con MusicGen
from audiocraft.models import MusicGen
from audiocraft.data.audio import audio_write
import os
import torchaudio
import librosa
import pyloudnorm as pyln

#viene creato un modello già addestrato con MusicGen
modello = MusicGen.get_pretrained('small')
modello.set_generation_params(duration=10)

#viene generata una traccia in modo casuale grazie al modello
traccia = modello.generate_unconditional(1)
audio_write("traccia", traccia[0], sample_rate = modello.sample_rate)
-----
#upsampling e normalizzazione a 44.1 kHz e LUFS -14
import soundfile as sf

tr_orig, sr_orig = librosa.load("traccia.wav", sr = None)
sf.write("traccia.wav", tr_orig, sr_orig)

#viene aumentata la frequenza della traccia originale a 44.1 kHz
waveform, sr = torchaudio.load("traccia.wav")
resampler = torchaudio.transforms.Resample(orig_freq = sr, new_freq = 44100)
waveform_up = resampler(waveform).squeeze().numpy()
sf.write("traccia_ups.wav", waveform_up, 44100)

#viene normalizzato il valore dei LUFS della traccia upsampled
tr_up, sr = sf.read("traccia_ups.wav")
meter = pyln.Meter(sr)
loudness = meter.integrated_loudness(tr_up)
tr_norm = pyln.normalize.loudness(tr_up, loudness, -14.0)
sf.write("traccia_norm.wav", tr_norm, sr)
-----
#dereverbering
import scipy.signal as signal

#viene creato un filtro sos per rimuovere le code di riverbero
tr_norm, sr = librosa.load("traccia_norm.wav", sr = None)
sos = signal.butter(N=4, Wn=450, btype="highpass", fs=sr, output= "sos")

#viene filtrata la traccia
tr_der = signal.sosfilt(sos, tr_norm)
sf.write("traccia_der.wav", tr_der, sr)
-----
#pulizia audio
from scipy.ndimage import median_filter

#viene creato un filtro per pulire gli artefatti audio
tr_dirt, sr = librosa.load("traccia_der.wav", sr=None)
tr_clean = median_filter(tr_dirt, size=3)

sf.write("traccia_clean.wav", tr_clean, sr)

"""METRICHE DI CONFRONTO"""

#confronto uditivo
from IPython.display import display, Audio

print("Traccia Originale")
display(Audio("traccia.wav"))
print("Traccia Finale")
display(Audio("traccia_clean.wav"))
-----
#confronto visivo con spettrogrammi e controfase
import librosa.display
import matplotlib.pyplot as plt
import numpy as np

t_orig, s_orig = librosa.load("traccia_norm.wav", sr=None)
t_clean, s_clean = librosa.load("traccia_clean.wav", sr=None)

#vengono ritagliate le tracce alla stessa lunghezza minima
min_len = min(len(t_orig), len(t_clean))
t_orig = t_orig[:min_len]
t_clean = t_clean[:min_len]

#viene posto t_clean in controfase
t_inv = -t_clean

#viene calcolato il residuo come originale + controfase
res = t_orig + t_inv

#funzione per creare gli spettrogrammi
def plot_spectrogram(y, sr, title, subplot_index):
    plt.subplot(3, 1, subplot_index)
    spet = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
    librosa.display.specshow(spet, sr=sr, x_axis='time', y_axis='mel')
    plt.title(title)
    plt.colorbar(format="%+2.0f dB")

#vengono creati gli spettrogrammi per ogni traccia
plt.figure(figsize=(12, 10))
plot_spectrogram(t_orig, s_orig, "Traccia originale", 1)
plot_spectrogram(t_clean, s_clean, "Traccia migliorata", 2)
plot_spectrogram(res, s_clean, "Controfase", 3)
plt.tight_layout()
plt.show()
-----
#Signal-to-Noise Ratio (SNR)
tr1, sr= librosa.load("traccia.wav", sr=None)
tr2, sr= librosa.load("traccia_clean.wav", sr=None)

#viene portata la traccia originale alla stessa frequenza di quella finale per poter valuatre tramite SNR
waveform, sr = torchaudio.load("traccia.wav")
resampler = torchaudio.transforms.Resample(orig_freq = sr, new_freq = 44100)
waveform_up = resampler(waveform).squeeze().numpy()

#viene calcolato il valore SNR secondo il valore di noise
noise = waveform_up - tr2
snr = 10 * np.log10(np.mean(tr1**2) / np.mean(noise**2))
print(f"SNR: {snr: .2f} dB")
-----
#Log-Spectral Distance (LSD)
#funzione per calcolare il valoe LSD
def compute_lsd(tr1, tr2, sr, n_fft=512, hop_length=256):
  s1 = np.abs(librosa.stft(tr1, n_fft=n_fft, hop_length=hop_length)) +1e-8
  s2 = np.abs(librosa.stft(tr2, n_fft=n_fft, hop_length=hop_length)) +1e-8

  min_cols = min(s1.shape[1], s2.shape[1])
  s1 = s1[:, :min_cols]
  s2 = s2[:, :min_cols]

  log_s1 = 20 * np.log10(s1)
  log_s2 = 20 * np.log10(s2)

  lsd = np.mean(np.sqrt(np.mean((log_s1 - log_s2)**2, axis=0)))
  return lsd

tr_1, sr1 = librosa.load("traccia.wav", sr=None)
tr_2, sr2 = librosa.load("traccia_norm.wav", sr=None)

#viene calcolato il valore LSD tra le due tracce
lsd_risultato = compute_lsd(tr_1, tr_2, sr)
print(f"LSD: {lsd_risultato: .2f} dB")
-----
!pip install pesq
-----
#Perceprual Evaluation of Speech Quality (PESQ)
from pesq import pesq
from scipy.io import wavfile

sr_og, tr_og = wavfile.read("traccia_norm.wav")
sr_end, tr_end = wavfile.read("traccia_clean.wav")

#vengono portate le due tracce a 16 kHz per applicare la funzione pesq
tr_og = librosa.resample(y=tr_og.astype(np.float32), orig_sr=sr_og, target_sr=16000)
tr_end = librosa.resample(y=tr_end.astype(np.float32), orig_sr=sr_end, target_sr=16000)

#viene calcolato il valore PESQ
pesq_risultato = pesq(16000, tr_og, tr_end, "wb")
print(f"Risultato PESQ: {pesq_risultato}")
